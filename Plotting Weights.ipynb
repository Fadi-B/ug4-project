{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adff1046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from change_reg_support import *\n",
    "\n",
    "from models import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22794a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Constants\n",
    "\n",
    "DIM = 5\n",
    "#TRIALS = 5\n",
    "\n",
    "CONG_SIGNALS = 3\n",
    "\n",
    "#For historic\n",
    "ALL_MODELS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735f5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "traces = ['TMobile-LTE', 'TMobile-UMTS', 'ATT-LTE', 'Verizon-LTE', 'Verizon-EVDO']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Works =) !!\n",
    "model_dict = get_models_dict(HISTORIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['TMobile-UMTS']['TRIAL_2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec6fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "d, f = get_linear_model('TMobile-UMTS', drop=BW_IGNORE)\n",
    "\n",
    "print(\"STEP 1: {}\".format(d['STEP_1']['TRIAL_1'][0]))\n",
    "print(\"STEP 2: {}\".format(d['STEP_2']['TRIAL_1'][0]))\n",
    "print(\"STEP 3: {}\".format(d['STEP_3']['TRIAL_1'][0]))\n",
    "print(\"STEP 4: {}\".format(d['STEP_4']['TRIAL_1'][0]))\n",
    "print(\"STEP 5: {}\".format(d['STEP_5']['TRIAL_1'][0]))\n",
    "print(\"STEP 6: {}\".format(d['STEP_6']['TRIAL_1'][0]))\n",
    "print(\"STEP 7: {}\".format(d['STEP_7']['TRIAL_1'][0]))\n",
    "print(\"STEP 8: {}\".format(d['STEP_8']['TRIAL_1'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0e8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Will just compute the averages of the weights here\n",
    "def plot_weights_historic(model_dict, history):\n",
    "    \n",
    "    ROWS = 2\n",
    "    COLUMNS = 2\n",
    "\n",
    "    fig, axs = plt.subplots(ROWS, COLUMNS, figsize=(14, 8))\n",
    "    \n",
    "    traces_new = traces\n",
    "    \n",
    "    i = 0\n",
    "    #Plot weights for each trace on diff. plots for each iteration\n",
    "    for key in model_dict.keys():\n",
    "        \n",
    "        #if (key=='Verizon-EVDO' or key=='Verizon-LTE'):continue\n",
    "        \n",
    "        # The weights will be a 1x3*history, where each chunk is new weights for that history\n",
    "        # The bias weight is \"collectively learnt\" for the whole model and so we will mainly be\n",
    "        # focusing on the impact of the history on congestion signals\n",
    "        w_t = model_dict[key]['TRIAL_1'][ALL_MODELS][history - 1][0].reshape(history, CONG_SIGNALS) #3 as this is how many cong. signals we have\n",
    "        \n",
    "        #Forget about bias for now - since it is 'collectively learnt'\n",
    "        b_t = model_dict[key]['TRIAL_1'][ALL_MODELS][history - 1][1]\n",
    "            \n",
    "        \n",
    "        for j in range(1, TRIALS):\n",
    "    \n",
    "            w = model_dict[key]['TRIAL_{}'.format(j+1)][ALL_MODELS][history - 1][0].reshape(history, CONG_SIGNALS)\n",
    "            \n",
    "            # hstack w_t so we take average across columns as rows indicate history now\n",
    "            w_t = np.hstack((w_t, w))\n",
    "        \n",
    "        w_ave = np.empty((history, CONG_SIGNALS))\n",
    "        yerr = np.empty((history, CONG_SIGNALS))\n",
    "        \n",
    "        #After end of this loop w_ave will be history x cong signals matrix of averages across trials\n",
    "        for k in range(0, history):\n",
    "            \n",
    "            #Take all columns - will be in format [w0, w1, w2, w0, w1, w2 ...]\n",
    "            row = w_t[k,:].reshape(TRIALS, CONG_SIGNALS) #now we have weights overlapping\n",
    "            \n",
    "            ave = np.mean(row, axis=0)\n",
    "            \n",
    "            #Now we have the average of weights across this specific trial\n",
    "            w_ave[k] = ave\n",
    "            \n",
    "            #Error calc\n",
    "            yerr[k] = np.std(row, axis=0)\n",
    "            \n",
    "        w = w_ave\n",
    "\n",
    "        x_axis = np.arange(1,history+1)\n",
    "    \n",
    "        #weights\n",
    "        axs[0][1].scatter(x_axis, w[:,0], marker='x', label=traces[i])\n",
    "        axs[0][1].set_title(\"RTTGrad weight vs historic window\", pad=20)\n",
    "        axs[0][1].set_xlabel(\"Historic Window\")\n",
    "        axs[0][1].set_ylabel(\"RTTGrad weight (Mbit/s)\")\n",
    "    \n",
    "    \n",
    "        axs[1][0].scatter(x_axis, w[:,1], marker='x', label=traces[i])\n",
    "        axs[1][0].set_title(\"Queueing delay weight vs historic window\", pad=20)\n",
    "        axs[1][0].set_xlabel(\"Historic Window\")\n",
    "        axs[1][0].set_ylabel(\"Queueing delay weight (Mbit/s\\u00b2)\")\n",
    "        \n",
    "    \n",
    "    \n",
    "        axs[1][1].scatter(x_axis, w[:,2], marker='x', label=traces[i])\n",
    "        axs[1][1].set_title(\"Inter arrival time weight vs Historic Window\", pad=20)\n",
    "        axs[1][1].set_xlabel(\"Historic Window\")\n",
    "        axs[1][1].set_ylabel(\"Inter arrival time weight (Mbit/s\\u00b2)\")\n",
    "        \n",
    "        width = 1\n",
    "        cap = 3\n",
    "            \n",
    "        axs[0][1].errorbar(x_axis, w[:,0], yerr[:,0], capsize=cap, elinewidth=width)\n",
    "        axs[1][0].errorbar(x_axis, w[:,1], yerr[:,1], capsize=cap, elinewidth=width)\n",
    "        axs[1][1].errorbar(x_axis, w[:,2], yerr[:,2], capsize=cap, elinewidth=width)\n",
    "            \n",
    "        fig.tight_layout(pad=2.0)\n",
    "    \n",
    "        i = i + 1\n",
    "        \n",
    "        \n",
    "    axs[0][0].grid()\n",
    "    axs[0][1].grid()\n",
    "    axs[1][0].grid()\n",
    "    axs[1][1].grid()\n",
    "    \n",
    "    axs[0][0].legend()\n",
    "    axs[0][1].legend()\n",
    "    axs[1][0].legend()\n",
    "    axs[1][1].legend()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd859526",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights_historic(model_dict, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28294ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= model_dict['ATT-LTE']['TRIAL_1'][ALL_MODELS][5][0].reshape(6, CONG_SIGNALS)\n",
    "g= model_dict['ATT-LTE']['TRIAL_1'][ALL_MODELS][5][0].reshape(6, CONG_SIGNALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbad6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, elem in ['faf','faf']:\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f51065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently just for step_1 (t+1)\n",
    "model_dict_lin_0 = get_models_dict(LINEAR, timestep='STEP_0')\n",
    "model_dict_lin_1 = get_models_dict(LINEAR, timestep='STEP_1')\n",
    "model_dict_lin_2 = get_models_dict(LINEAR, timestep='STEP_2')\n",
    "model_dict_lin_3 = get_models_dict(LINEAR, timestep='STEP_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d37752a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "trace = 'TMobile-LTE'\n",
    "print(AVERAGE)\n",
    "a = model_dict_lin_0[trace]['TRIAL_{}'.format(AVERAGE)]\n",
    "b = model_dict_lin_1[trace]['TRIAL_{}'.format(AVERAGE)]\n",
    "c = model_dict_lin_2[trace]['TRIAL_{}'.format(AVERAGE)]\n",
    "d = model_dict_lin_3[trace]['TRIAL_{}'.format(AVERAGE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe60b50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([array([ 0.23476493, -0.00578074, -0.0043876 ]), array(0.65969322)],\n",
      "      dtype=object), 3.391485449278028, array([[ 3.62133333e+01,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.01350000e+03],\n",
      "       [ 3.62133333e+01, -1.06739000e-01,  3.12500000e+00,\n",
      "         1.09081000e+02],\n",
      "       [ 3.09866667e+01,  0.00000000e+00,  4.00000000e+00,\n",
      "         2.07786000e+01],\n",
      "       ...,\n",
      "       [ 2.66933333e+01, -2.95075000e-01,  9.32318000e+01,\n",
      "         2.48032000e-01],\n",
      "       [ 2.89333333e+01,  3.65849000e-01,  1.11161000e+02,\n",
      "         1.93288000e-01],\n",
      "       [ 2.74400000e+01,  3.67425000e-01,  1.37629000e+02,\n",
      "         2.05572000e-01]])]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be3771b3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([array([-0.11187212,  0.00070284,  0.00512004]), array(-0.08936614)],\n",
      "      dtype=object), 3.4163627329621282, array([[ 3.09866667e+01,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.01350000e+03],\n",
      "       [ 3.97600000e+01, -1.06739000e-01,  3.12500000e+00,\n",
      "         1.09081000e+02],\n",
      "       [ 3.49066667e+01,  0.00000000e+00,  4.00000000e+00,\n",
      "         2.07786000e+01],\n",
      "       ...,\n",
      "       [ 2.66933333e+01,  1.16698000e-01,  1.28176000e+02,\n",
      "         1.81450000e-01],\n",
      "       [ 2.89333333e+01, -4.95795000e-01,  1.00177000e+02,\n",
      "         6.34600000e-01],\n",
      "       [ 2.74400000e+01, -2.95075000e-01,  9.32318000e+01,\n",
      "         2.48032000e-01]])]\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0096c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_lin['Verizon-EVDO']['TRIAL_21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_dict_lin['TMobile-LTE']['TRIAL_45']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd37f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef0e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d81d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc103f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cdff0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights( model_dict, mode='average'):\n",
    "\n",
    "    ROWS = 2\n",
    "    COLUMNS = 2\n",
    "\n",
    "    fig, axs = plt.subplots(ROWS, COLUMNS, figsize=(14, 8))\n",
    "    \n",
    "    traces_new = traces\n",
    "    \n",
    "    if (mode=='all'):\n",
    "        \n",
    "        traces_new = []\n",
    "        \n",
    "        \n",
    "        for i in range(0, len(traces)):\n",
    "            \n",
    "            traces_new.append(np.repeat(traces[i], TRIALS))\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    #Plot weights for each trace on diff. plots for each iteration\n",
    "    for key in model_dict.keys():\n",
    "        \n",
    "        yerr = []\n",
    "\n",
    "        if (mode=='average'):\n",
    "        \n",
    "            w_t = model_dict[key]['TRIAL_1'][0][0]\n",
    "            b_t = model_dict[key]['TRIAL_1'][0][1]\n",
    "            \n",
    "            all_b = []\n",
    "        \n",
    "            for j in range(1, TRIALS):\n",
    "    \n",
    "                w = model_dict[key]['TRIAL_{}'.format(j+1)][0][0]\n",
    "                b = model_dict[key]['TRIAL_{}'.format(j+1)][0][1]\n",
    "            \n",
    "                w_t = np.vstack((w_t, w))\n",
    "                b_t = b_t + b\n",
    "                \n",
    "                #To calculate error\n",
    "                all_b.append(b_t)\n",
    "            \n",
    "            processed = []\n",
    "            processed.append(w_t[:,0])\n",
    "            processed.append(w_t[:,1])\n",
    "            processed.append(w_t[:,2])\n",
    "    \n",
    "            w_ave = np.mean(processed, axis=1)\n",
    "            \n",
    "            b_ave = b_t / TRIALS\n",
    "            \n",
    "            #Error calc\n",
    "            yerr.append(np.std(all_b))\n",
    "            yerr.append(np.std(processed[0]))\n",
    "            yerr.append(np.std(processed[1]))\n",
    "            yerr.append(np.std(processed[2]))\n",
    "            \n",
    "        elif (mode=='all'):\n",
    "            \n",
    "            w_ave = []\n",
    "            b_ave = []\n",
    "            \n",
    "            for j in range(0, TRIALS):\n",
    "                \n",
    "                w = model_dict[key]['TRIAL_{}'.format(j+1)][0][0]\n",
    "                b = model_dict[key]['TRIAL_{}'.format(j+1)][0][1]\n",
    "            \n",
    "                w_ave.append(w)\n",
    "                b_ave.append(b)\n",
    "            \n",
    "            stacked = np.array(w_ave)\n",
    "            \n",
    "            processed = []\n",
    "            processed.append(stacked[:,0])\n",
    "            processed.append(stacked[:,1])\n",
    "            processed.append(stacked[:,2])\n",
    "            \n",
    "            w_ave = processed\n",
    "            \n",
    "        w = w_ave\n",
    "        b = b_ave\n",
    "    \n",
    "        #bias\n",
    "        axs[0][0].scatter(traces_new[i], b, marker='x')\n",
    "        axs[0][0].set_title(\"Bias weight vs input trace\", pad=20)\n",
    "        axs[0][0].set_xlabel(\"Trace\")\n",
    "        axs[0][0].set_ylabel(\"Bias weight (Mbit/s)\")\n",
    "\n",
    "    \n",
    "    \n",
    "        #weights\n",
    "        axs[0][1].scatter(traces_new[i], w[0], marker='x')\n",
    "        axs[0][1].set_title(\"RTTGrad weight vs input trace\", pad=20)\n",
    "        axs[0][1].set_xlabel(\"Trace\")\n",
    "        axs[0][1].set_ylabel(\"RTTGrad weight (Mbit/s)\")\n",
    "    \n",
    "    \n",
    "        axs[1][0].scatter(traces_new[i], w[1], marker='x')\n",
    "        axs[1][0].set_title(\"Queueing delay weight vs input trace\", pad=20)\n",
    "        axs[1][0].set_xlabel(\"Trace\")\n",
    "        axs[1][0].set_ylabel(\"Queueing delay weight (Mbit/s\\u00b2)\")\n",
    "        \n",
    "    \n",
    "    \n",
    "        axs[1][1].scatter(traces_new[i], w[2], marker='x')\n",
    "        axs[1][1].set_title(\"Inter arrival time weight vs input trace\", pad=20)\n",
    "        axs[1][1].set_xlabel(\"Trace\")\n",
    "        axs[1][1].set_ylabel(\"Inter arrival time weight (Mbit/s\\u00b2)\")\n",
    "        \n",
    "        \n",
    "        if (mode=='average'):\n",
    "            width = 1\n",
    "            cap = 3\n",
    "            axs[0][0].errorbar(traces_new[i], b, yerr[0], capsize=cap, elinewidth=width)\n",
    "            axs[0][1].errorbar(traces_new[i], w[0], yerr[1], capsize=cap, elinewidth=width)\n",
    "            axs[1][0].errorbar(traces_new[i], w[1], yerr[2], capsize=cap, elinewidth=width)\n",
    "            axs[1][1].errorbar(traces_new[i], w[2], yerr[3], capsize=cap, elinewidth=width)\n",
    "            \n",
    "        fig.tight_layout(pad=2.0)\n",
    "    \n",
    "        i = i + 1\n",
    "        \n",
    "        \n",
    "    axs[0][0].grid()\n",
    "    axs[0][1].grid()\n",
    "    axs[1][0].grid()\n",
    "    axs[1][1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030b741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights(model_dict_lin, mode='all')\n",
    "plot_weights(model_dict_lin, mode='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_lin_2 = get_models_dict(LINEAR, timestep='STEP_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights(model_dict_lin_2, mode='average')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1e4d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from algorithm_evaluator import *\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "# RMSEs for the different traces using diff Sprout Variants\n",
    "rmses_fadi = []\n",
    "rmses_ewma = []\n",
    "rmses_ma = []\n",
    "\n",
    "for trace in traces:\n",
    "    \n",
    "    rmse_fadi = model_dict_lin[trace]['TRIAL_11'][1]\n",
    "    rmse_ewma = get_rmse_sprout_ewma(trace, alpha=1/4)\n",
    "    #rmse_ma = get_rmse_sprout_ewma(trace, alpha=1)\n",
    "    \n",
    "    rmses_fadi.append(rmse_fadi)\n",
    "    rmses_ewma.append(rmse_ewma)\n",
    "    #rmses_ma.append(rmse_ma)\n",
    "\n",
    "axs.scatter(traces, rmses_fadi, marker='x', label=\"Sprout-Fadi\")\n",
    "axs.scatter(traces, rmses_ewma, marker='x', label=\"Sprout-EWMA\")\n",
    "#axs.scatter(traces, rmses_ma, marker='x', label=\"Sprout-MA\")\n",
    "\n",
    "axs.legend()\n",
    "\n",
    "\n",
    "axs.set_title(\"RMSE vs input trace\", pad=20)\n",
    "axs.set_xlabel(\"Trace\")\n",
    "axs.set_ylabel(\"RMSE\")\n",
    "\n",
    "#axs.set_ylim(0,4)\n",
    "\n",
    "axs.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sprout_ewma_rmse_vs_alpha('TMobile-UMTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for trace in traces:\n",
    "    \n",
    "    value = get_min_ewma_alpha(trace)\n",
    "\n",
    "    print(\"{}: {}\".format(trace, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sprout_ewma_rmse_vs_alpha('Verizon-LTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60555466",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Investigating consistency of estimated noise covariances\n",
    "\n",
    "from noise_estimator import *\n",
    "\n",
    "def plot_noise_estimations(mode='all'):\n",
    "    \n",
    "    ROWS = 2\n",
    "    COLUMNS = 2\n",
    "    \n",
    "    fig, axs = plt.subplots(ROWS, COLUMNS, figsize=(14, 8))\n",
    "\n",
    "    sys_variances = {}\n",
    "    obs_variances = {}\n",
    "\n",
    "    ratio = {}\n",
    "\n",
    "    for trace in traces:\n",
    "    \n",
    "        noise_dict = get_noise_variances(trace)\n",
    "    \n",
    "        trials_sys = []\n",
    "        trials_obs = []\n",
    "    \n",
    "        trials_ratio = []\n",
    "    \n",
    "        for i in range(0, TRIALS):\n",
    "    \n",
    "            sys_var = noise_dict['TRIAL_{}'.format(i+1)][0]\n",
    "            obs_var = noise_dict['TRIAL_{}'.format(i+1)][1]\n",
    "        \n",
    "            trials_sys.append(sys_var)\n",
    "            trials_obs.append(obs_var)\n",
    "        \n",
    "            trials_ratio.append(sys_var/obs_var)\n",
    "    \n",
    "        sys_variances[trace] = trials_sys\n",
    "        obs_variances[trace] = trials_obs\n",
    "        ratio[trace] = trials_ratio\n",
    "\n",
    "    traces_new = []\n",
    "    ratio_data = []\n",
    "    \n",
    "    if (mode=='all'):\n",
    "        \n",
    "        size = len(traces)\n",
    "        \n",
    "        for j in range(0, size):\n",
    "            \n",
    "            traces_new.append(np.repeat(traces[j], size))\n",
    "            sys_var = sys_variances\n",
    "            obs_var = obs_variances\n",
    "            ratio_data = ratio\n",
    "    \n",
    "    elif (mode=='average'):\n",
    "        \n",
    "        traces_new = traces\n",
    "        \n",
    "        sys_var = {}\n",
    "        obs_var = {}\n",
    "        ratio_data = {}\n",
    "        \n",
    "        yerr = {}\n",
    "        yerr['sys'] = {}\n",
    "        yerr['obs'] = {}\n",
    "        yerr['ratio'] = {}\n",
    "        \n",
    "        for key in sys_variances.keys():\n",
    "            \n",
    "            sys_var[key] = np.mean(sys_variances[key])\n",
    "            obs_var[key] = np.mean(obs_variances[key])\n",
    "            ratio_data[key] = np.mean(ratio[key])\n",
    "            \n",
    "            yerr['sys'][key] = np.std(sys_variances[key])\n",
    "            yerr['obs'][key] = np.std(obs_variances[key])\n",
    "            yerr['ratio'][key] = np.std(ratio[key])\n",
    "            \n",
    "        \n",
    "            \n",
    "#axs.scatter(traces, sys_variances, marker='x')\n",
    "#axs.scatter(traces, obs_variances, marker='x')\n",
    "\n",
    "    print(\"Sys Var\")\n",
    "    print(sys_var)\n",
    "    \n",
    "    print(\"Obs Var\")\n",
    "    print(obs_var)\n",
    "\n",
    "    for k in range(0, len(traces)):\n",
    "        \n",
    "        #print(len(traces_new[k]))\n",
    "        #print(len(sys_var[traces[k]]))\n",
    "        axs[0][0].scatter(traces_new[k], sys_var[traces[k]], marker='x')\n",
    "        axs[0][1].scatter(traces_new[k], obs_var[traces[k]], marker='x')\n",
    "        axs[1][0].scatter(traces_new[k], ratio_data[traces[k]], marker='x')\n",
    "        \n",
    "        if (mode == 'average'):\n",
    "            \n",
    "            #print(yerr['sys'][traces[k]])\n",
    "            width = 1\n",
    "            cap = 3\n",
    "            axs[0][0].errorbar(traces_new[k], sys_var[traces[k]], yerr['sys'][traces[k]], capsize=cap, elinewidth=width)\n",
    "            axs[0][1].errorbar(traces_new[k], obs_var[traces[k]], yerr['obs'][traces[k]], capsize=cap, elinewidth=width)\n",
    "            axs[1][0].errorbar(traces_new[k], ratio_data[traces[k]], yerr['ratio'][traces[k]], capsize=cap, elinewidth=width)\n",
    "\n",
    "        \n",
    "    axs[0][0].set_title(\"System Noise vs input trace\", pad=20)\n",
    "    axs[0][1].set_title(\"Observation Noise vs input trace\", pad=20)\n",
    "    axs[1][0].set_title(\"Noise Ratio vs input trace\", pad=20)\n",
    "    \n",
    "    axs[0][0].set_xlabel(\"Trace\")\n",
    "    axs[0][1].set_xlabel(\"Trace\")\n",
    "    axs[1][0].set_xlabel(\"Trace\")\n",
    "    \n",
    "    axs[0][0].set_ylabel(\"System Noise (Mbit/s)\")\n",
    "    axs[0][1].set_ylabel(\"Noise Ratio (Mbit/s)\")\n",
    "    axs[1][0].set_ylabel(\"Noise Ratio (Dimensionless)\")\n",
    "\n",
    "    axs[1][0].set_ylim(-1, 4)\n",
    "\n",
    "    axs[0][0].grid()\n",
    "    axs[0][1].grid()\n",
    "    axs[1][0].grid()\n",
    "    \n",
    "    fig.tight_layout(pad=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_noise_estimations(mode='average')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae42e72",
   "metadata": {},
   "source": [
    "plot_noise_estimations(mode='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Plotting the correlation between link capacity and different congestion signals ###\n",
    "\n",
    "ROWS = 2\n",
    "COLUMNS = 2\n",
    "\n",
    "fig, axs = plt.subplots(ROWS, COLUMNS, figsize=(14, 8))\n",
    "\n",
    "i = 0\n",
    "#Plot weights for each trace on diff. plots for each iteration\n",
    "for key in model_dict.keys():\n",
    "    \n",
    "    data = model_dict[key]['TRIAL_1'][2]\n",
    "    \n",
    "    corr = np.corrcoef(data.T)\n",
    "    \n",
    "    corr_through_rtt = corr[0][1]\n",
    "    corr_through_queue = corr[0][2]\n",
    "    corr_through_inter = corr[0][3]\n",
    "    \n",
    "    #bias\n",
    "    axs[0][0].scatter(traces[i], corr_through_rtt, marker='x')\n",
    "    axs[0][0].set_title(\"Correlation coefficient between link capacity and RTT gradient\", pad=20)\n",
    "    axs[0][0].set_xlabel(\"Trace\")\n",
    "    axs[0][0].set_ylabel(\"Correlation coefficient\")\n",
    "    \n",
    "    \n",
    "    #weights\n",
    "    axs[0][1].scatter(traces[i], corr_through_queue, marker='x')\n",
    "    axs[0][1].set_title(\"Correlation coefficient between link capacity and queuing delay\", pad=20)\n",
    "    axs[0][1].set_xlabel(\"Trace\")\n",
    "    axs[0][1].set_ylabel(\"Correlation coefficient\")\n",
    "    \n",
    "    \n",
    "    axs[1][0].scatter(traces[i], corr_through_inter, marker='x')\n",
    "    axs[1][0].set_title(\"Correlation coefficient between link capacity and inter arrival time\", pad=20)\n",
    "    axs[1][0].set_xlabel(\"Trace\")\n",
    "    axs[1][0].set_ylabel(\"Correlation coefficient\")\n",
    "    \n",
    "    \n",
    "    #axs[1][1].scatter(traces[i], w[2], marker='x')\n",
    "    #axs[1][1].set_title(\"Inter arrival time weight vs input trace\", pad=20)\n",
    "    #axs[1][1].set_xlabel(\"Trace\")\n",
    "    #axs[1][1].set_ylabel(\"Inter arrival time weight (Mbit/s\\u00b2)\")\n",
    "    \n",
    "    fig.tight_layout(pad=2.0)\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "axs[0][0].grid()\n",
    "axs[0][1].grid()\n",
    "axs[1][0].grid()\n",
    "#axs[1][1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a581506",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model_dict['TMobile-UMTS'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e38d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35617ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and processing relevant data\n",
    "data = get_all_trial_datasets()\n",
    "processed_train_data = get_all_trial_processed_datasets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e39499",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_processed = process_labels_and_dataset(processed_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_coef_inter_through = []\n",
    "\n",
    "for key in model_dict.keys():\n",
    "\n",
    "    corr_trials = []\n",
    "    corr_coef = 0\n",
    "    #Taking an average of the trials\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        \n",
    "        \n",
    "        X = new_processed[key][PROCESSED_DATASETS][i][:,:]\n",
    "        \n",
    "        corr = np.corrcoef(X.T)\n",
    "        \n",
    "        corr_trials.append(corr[0][3])\n",
    "        \n",
    "        #corr_coef = corr_coef + corr[0][3]\n",
    "    \n",
    "    #corr_coef = corr_coef / 5\n",
    "    \n",
    "    corr_coef_inter_through.append((key, corr_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f30b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coef_inter_through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261206e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(ROWS, COLUMNS, figsize=(14, 8))\n",
    "\n",
    "y_axis = [x[1] for x in corr_coef_inter_through]\n",
    "\n",
    "x_trials = ['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4', 'Trial 5']\n",
    "    \n",
    "axs[0][0].scatter(x_trials, y_axis[0], marker='x')\n",
    "axs[0][0].set_xlabel(\"Trial Number\")\n",
    "axs[0][0].set_ylabel(\"Correlation coefficient\")\n",
    "axs[0][0].set_title(\"TMobile-LTE: Corr. coeff. bandwidth and inter time\", pad=20)\n",
    "\n",
    "axs[0][1].scatter(x_trials, y_axis[1], marker='x')\n",
    "axs[0][1].set_xlabel(\"Trial Number\")\n",
    "axs[0][1].set_ylabel(\"Correlation coefficient\")\n",
    "axs[0][1].set_title(\"TMobile-UMTS: Corr. coeff. bandwidth and inter time\", pad=20)\n",
    "\n",
    "axs[1][0].scatter(x_trials, y_axis[2], marker='x')\n",
    "axs[1][0].set_xlabel(\"Trial Number\")\n",
    "axs[1][0].set_ylabel(\"Correlation coefficient\")\n",
    "axs[1][0].set_title(\"ATT-LTE: Corr. coeff. bandwidth and inter time\", pad=20)\n",
    "\n",
    "axs[1][1].scatter(x_trials, y_axis[3], marker='x')\n",
    "axs[1][1].set_xlabel(\"Trial Number\")\n",
    "axs[1][1].set_ylabel(\"Correlation coefficient\")\n",
    "axs[1][1].set_title(\"Verizon-LTE: Corr. coeff. bandwidth and inter time\", pad=20)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "axs[0][0].grid()\n",
    "axs[0][1].grid()\n",
    "axs[1][0].grid()\n",
    "axs[1][1].grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = [x[0] for x in corr_coef_inter_through]\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "axs.errorbar(x_axis, np.mean(y_axis, 1), np.std(y_axis, 1), capsize=3, elinewidth=1, ls='none')\n",
    "axs.scatter(x_axis, np.mean(y_axis, 1), marker='x')\n",
    "\n",
    "#axs[0][0].errorbar(traces_new[k], sys_var[traces[k]], yerr['sys'][traces[k]], capsize=cap, elinewidth=width)\n",
    "\n",
    "axs.set_xlabel(\"Trace\")\n",
    "axs.set_ylabel(\"Correlation coefficient\")\n",
    "axs.set_title(\"Corr. coeff. bandwidth and inter time vs input trace\", pad=20)\n",
    "axs.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bdb6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(y_axis, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c833217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404a51e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
